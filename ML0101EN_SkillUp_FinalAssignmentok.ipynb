{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "### Final Project: Classification with Python",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Surpress warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport sklearn.metrics as metrics",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "### Importing the Datase",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv'",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "await download(path, \"Weather_Data.csv\")\nfilename =\"Weather_Data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(\"Weather_Data.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n\n   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n0             41          S        SSW  ...           92           84   \n1             41          W          E  ...           83           73   \n2             41        ESE        ESE  ...           88           86   \n3             41        NNE          E  ...           83           90   \n4             41        NNE          W  ...           88           74   \n\n   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n\n   RainTomorrow  \n0           Yes  \n1           Yes  \n2           Yes  \n3           Yes  \n4           Yes  \n\n[5 rows x 22 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>WindDir3pm</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2/1/2008</td>\n      <td>19.5</td>\n      <td>22.4</td>\n      <td>15.6</td>\n      <td>6.2</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>S</td>\n      <td>SSW</td>\n      <td>...</td>\n      <td>92</td>\n      <td>84</td>\n      <td>1017.6</td>\n      <td>1017.4</td>\n      <td>8</td>\n      <td>8</td>\n      <td>20.7</td>\n      <td>20.9</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2/2/2008</td>\n      <td>19.5</td>\n      <td>25.6</td>\n      <td>6.0</td>\n      <td>3.4</td>\n      <td>2.7</td>\n      <td>W</td>\n      <td>41</td>\n      <td>W</td>\n      <td>E</td>\n      <td>...</td>\n      <td>83</td>\n      <td>73</td>\n      <td>1017.9</td>\n      <td>1016.4</td>\n      <td>7</td>\n      <td>7</td>\n      <td>22.4</td>\n      <td>24.8</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2/3/2008</td>\n      <td>21.6</td>\n      <td>24.5</td>\n      <td>6.6</td>\n      <td>2.4</td>\n      <td>0.1</td>\n      <td>W</td>\n      <td>41</td>\n      <td>ESE</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>88</td>\n      <td>86</td>\n      <td>1016.7</td>\n      <td>1015.6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>23.5</td>\n      <td>23.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2/4/2008</td>\n      <td>20.2</td>\n      <td>22.8</td>\n      <td>18.8</td>\n      <td>2.2</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>NNE</td>\n      <td>E</td>\n      <td>...</td>\n      <td>83</td>\n      <td>90</td>\n      <td>1014.2</td>\n      <td>1011.8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>21.4</td>\n      <td>20.9</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2/5/2008</td>\n      <td>19.7</td>\n      <td>25.7</td>\n      <td>77.4</td>\n      <td>4.8</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>NNE</td>\n      <td>W</td>\n      <td>...</td>\n      <td>88</td>\n      <td>74</td>\n      <td>1008.3</td>\n      <td>1004.8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>22.5</td>\n      <td>25.5</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "### Data Preprocessing",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### One Hot Encoding\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "#### Training Data and Test Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.drop('Date',axis=1,inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed = df_sydney_processed.astype(float)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": "features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\nY = df_sydney_processed['RainTomorrow']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "#### Linear Regression",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### Q1) Use the train_test_split function to split the features and Y dataframes with a test_size of 0.2 and the random_state set to 10",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\n# Split data\nX_train, X_test, Y_train, Y_test = train_test_split(features, Y, test_size=0.2, random_state=10)\n\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"Y_train shape:\", Y_train.shape)\nprint(\"Y_test shape:\", Y_test.shape)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "X_train shape: (2616, 66)\nX_test shape: (655, 66)\nY_train shape: (2616,)\nY_test shape: (655,)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "##### Q2) Create and train a Linear Regression model called LinearReg using the training data (x_train, y_train).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import LinearRegression\n\n# Create the model\nLinearReg = LinearRegression()\n\n# Train the model\nLinearReg.fit(X_train, Y_train)\n\n# Display the coefficients\nprint(\"Coefficients:\", LinearReg.coef_)\nprint(\"Intercept:\", LinearReg.intercept_)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Coefficients: [-2.36883601e-02  1.30031554e-02  7.30154915e-04  6.49290860e-03\n -3.51614515e-02  4.23841910e-03  1.82843563e-03  7.89794445e-04\n  9.55888360e-04  8.56007751e-03  7.70261345e-03 -9.24932344e-03\n -8.87528023e-03  1.00457553e-02  1.44651992e-02 -3.48325241e-03\n  1.03190076e+10  1.03190076e+10 -4.35428535e+09 -4.35428535e+09\n -4.35428535e+09 -4.35428535e+09 -4.35428535e+09 -4.35428535e+09\n -4.35428535e+09 -4.35428535e+09 -4.35428535e+09 -4.35428535e+09\n -4.35428535e+09 -4.35428535e+09 -4.35428535e+09 -4.35428535e+09\n -4.35428535e+09 -4.35428535e+09  4.72755310e+09  4.72755310e+09\n  4.72755310e+09  4.72755310e+09  4.72755310e+09  4.72755310e+09\n  4.72755310e+09  4.72755310e+09  4.72755310e+09  4.72755310e+09\n  4.72755310e+09  4.72755310e+09  4.72755310e+09  4.72755310e+09\n  4.72755310e+09  4.72755310e+09 -1.18315500e+10 -1.18315500e+10\n -1.18315500e+10 -1.18315500e+10 -1.18315500e+10 -1.18315500e+10\n -1.18315500e+10 -1.18315500e+10 -1.18315500e+10 -1.18315500e+10\n -1.18315500e+10 -1.18315500e+10 -1.18315500e+10 -1.18315500e+10\n -1.18315500e+10 -1.18315500e+10]\nIntercept: 1139274582.2150812\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "##### Q3) Now use the predict method on the testing data (x_test) and save it to the array predictions",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Make predictions on the testing data\npredictions = LinearReg.predict(X_test)\n\n# Display the first few predictions\nprint(predictions[:5])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0.13185596 0.27621174 0.97815037 0.28743076 0.13245678]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "##### Q4) Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Calculate metrics\nmse = mean_squared_error(Y_test, predictions)\nmae = mean_absolute_error(Y_test, predictions)\nr2 = r2_score(Y_test, predictions)\n\n# Display metrics\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"Mean Absolute Error (MAE):\", mae)\nprint(\"R-squared (R2):\", r2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error (MSE): 0.1157209828234031\nMean Absolute Error (MAE): 0.256318933909176\nR-squared (R2): 0.4271301272061002\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "##### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\n# dictionary withmetrics\nmetrics_dict = {\n    \"Metric\": [\"Mean Absolute Error (MAE)\", \"Mean Squared Error (MSE)\", \"R-squared (R2)\"],\n    \"Value\": [mae, mse, r2]\n}\n\n# Convert dictionary into a DataFrame\nmetrics_df = pd.DataFrame(metrics_dict)\n\nprint(metrics_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                      Metric     Value\n0  Mean Absolute Error (MAE)  0.256319\n1   Mean Squared Error (MSE)  0.115721\n2             R-squared (R2)  0.427130\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": "### KNN",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### Q6) Create and train a KNN model called KNN using the training data (x_train, y_train) with the n_neighbors parameter set to 4",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\n\n# Create the KNN model\nKNN = KNeighborsClassifier(n_neighbors=4)\n\n# Train the model\nKNN.fit(X_train, Y_train)\n\n# Display the model parameters\nprint(KNN)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "KNeighborsClassifier(n_neighbors=4)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": "##### Q7) Now use the predict method on the testing data (x_test) and save it to the array predictions.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Make predictions on the testing data\npredictions = KNN.predict(X_test)\n\n# Display the first few predictions\nprint(predictions[:5])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0. 0. 1. 0. 0.]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "##### Q8) Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import jaccard_score, f1_score, log_loss, confusion_matrix, accuracy_score\n\n# Calculate metrics\njaccard = jaccard_score(Y_test, predictions)\nf1 = f1_score(Y_test, predictions)\nlogloss = log_loss(Y_test, predictions)\nconf_matrix = confusion_matrix(Y_test, predictions)\naccuracy = accuracy_score(Y_test, predictions)\n\n# Display the metrics\nprint(\"Jaccard Score:\", jaccard)\nprint(\"F1 Score:\", f1)\nprint(\"Log Loss:\", logloss)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\nprint(\"Accuracy Score:\", accuracy)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Jaccard Score: 0.4251207729468599\nF1 Score: 0.5966101694915255\nLog Loss: 6.548388936343421\nConfusion Matrix:\n [[448  23]\n [ 96  88]]\nAccuracy Score: 0.8183206106870229\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "### Decision Tree",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### Q9) Create and train a Decision Tree model called Tree using the training data (x_train, y_train).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\n\n# Create the Decision Tree model\nTree = DecisionTreeClassifier()\n\n# Train the model\nTree.fit(X_train, Y_train)\n\n# Display the model parameters\nprint(Tree)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "DecisionTreeClassifier()\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "##### Q10) Now use the predict method on the testing data (x_test) and save it to the array predictions",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Make predictions on the testing data\npredictions = Tree.predict(X_test)\n\n# Display the first few predictions\nprint(predictions[:5])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0. 0. 1. 0. 0.]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "##### Q11) Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import jaccard_score, f1_score, log_loss, confusion_matrix, accuracy_score\n\n# Calculate metrics\njaccard = jaccard_score(Y_test, predictions)\nf1 = f1_score(Y_test, predictions)\nlogloss = log_loss(Y_test, predictions)\nconf_matrix = confusion_matrix(Y_test, predictions)\naccuracy = accuracy_score(Y_test, predictions)\n\n# Displaymetrics\nprint(\"Jaccard Score:\", jaccard)\nprint(\"F1 Score:\", f1)\nprint(\"Log Loss:\", logloss)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\nprint(\"Accuracy Score:\", accuracy)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Jaccard Score: 0.3857677902621723\nF1 Score: 0.5567567567567567\nLog Loss: 9.024670466893456\nConfusion Matrix:\n [[388  83]\n [ 81 103]]\nAccuracy Score: 0.749618320610687\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": "### Logistic Regression",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### Q12) Use the train_test_split function to split the features and Y dataframes with a test_size of 0.2 and the random_state set to 1",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\n# Splitdata\nX_train, X_test, Y_train, Y_test = train_test_split(features, Y, test_size=0.2, random_state=1)\n\n# Display the shapes of the resulting datasets\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"Y_train shape:\", Y_train.shape)\nprint(\"Y_test shape:\", Y_test.shape)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "X_train shape: (2616, 66)\nX_test shape: (655, 66)\nY_train shape: (2616,)\nY_test shape: (655,)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "##### Q13) Create and train a LogisticRegression model called LR using the training data (x_train, y_train) with the solver parameter set to liblinea",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\n\n# Create the Logistic Regression model\nLR = LogisticRegression(solver='liblinear')\n\n# Train the model\nLR.fit(X_train, Y_train)\n\n# Display the model parameters\nprint(LR)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "LogisticRegression(solver='liblinear')\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": "##### Q14) Now, use the predict and predict_proba methods on the testing data (x_test) and save it as 2 arrays predictions and predict_proba.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Make predictions on the testing data\npredictions = LR.predict(X_test)\n\n# Get the probability estimates for the testing data\npredict_proba = LR.predict_proba(X_test)\n\n# Display the first few predictions and probability estimates\nprint(\"Predictions:\", predictions[:5])\nprint(\"Probability Estimates:\\n\", predict_proba[:5])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Predictions: [0. 0. 1. 0. 0.]\nProbability Estimates:\n [[0.92234371 0.07765629]\n [0.8260171  0.1739829 ]\n [0.04337676 0.95662324]\n [0.80110447 0.19889553]\n [0.96128058 0.03871942]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "source": "##### Q15) Using the predictions, predict_proba and the y_test dataframe calculate the value for each metric using the appropriate function.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import jaccard_score, f1_score, log_loss, confusion_matrix, accuracy_score\n\n# Calculate metrics\njaccard = jaccard_score(Y_test, predictions)\nf1 = f1_score(Y_test, predictions)\nlogloss = log_loss(Y_test, predict_proba)\nconf_matrix = confusion_matrix(Y_test, predictions)\naccuracy = accuracy_score(Y_test, predictions)\n\n# Display metrics\nprint(\"Jaccard Score:\", jaccard)\nprint(\"F1 Score:\", f1)\nprint(\"Log Loss:\", logloss)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\nprint(\"Accuracy Score:\", accuracy)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Jaccard Score: 0.511520737327189\nF1 Score: 0.676829268292683\nLog Loss: 0.38103765010675233\nConfusion Matrix:\n [[438  35]\n [ 71 111]]\nAccuracy Score: 0.8381679389312977\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": "### SVM",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### Q16) Create and train a SVM model called SVM using the training data (x_train, y_train)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import svm\n\n# Create the SVM model-(Support Vector Classifier)\nSVM = svm.SVC()\n\n# Train the model\nSVM.fit(X_train, Y_train)\n\n# Display the model parameters\nprint(SVM)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "SVC()\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": "##### Q17) Now use the predict method on the testing data (x_test) and save it to the array predictions.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Make predictions on the testing data\npredictions = SVM.predict(X_test)\n\n# Display the first few predictions\nprint(predictions[:5])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0. 0. 0. 0. 0.]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": "##### Q18) Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import jaccard_score, f1_score, log_loss, confusion_matrix, accuracy_score\n\n# Calculate metrics\njaccard = jaccard_score(Y_test, predictions)\nf1 = f1_score(Y_test, predictions)\nlogloss = log_loss(Y_test, predictions)\nconf_matrix = confusion_matrix(Y_test, predictions)\naccuracy = accuracy_score(Y_test, predictions)\n\n# Display the metrics\nprint(\"Jaccard Score:\", jaccard)\nprint(\"F1 Score:\", f1)\nprint(\"Log Loss:\", logloss)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\nprint(\"Accuracy Score:\", accuracy)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Jaccard Score: 0.0\nF1 Score: 0.0\nLog Loss: 10.125240036026804\nConfusion Matrix:\n [[471   0]\n [184   0]]\nAccuracy Score: 0.7190839694656489\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": "print(\"SVM_Accuracy_Score =\", accuracy)\nprint(\"SVM_JaccardIndex =\", jaccard)\nprint(\"SVM_F1_Score =\", f1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "SVM_Accuracy_Score = 0.7190839694656489\nSVM_JaccardIndex = 0.0\nSVM_F1_Score = 0.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "source": "##### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.metrics import accuracy_score, jaccard_score, f1_score, log_loss\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Assuming you have already calculated these metrics for each model\n# Replace the following values with your actual calculated metrics\n\n# For Linear Regression (regression metrics)\nmse = mean_squared_error(Y_test, predictions)\nmae = mean_absolute_error(Y_test, predictions)\nr2 = r2_score(Y_test, predictions)\n\n\n# For classification models\nKNN_Accuracy = accuracy_score(Y_test, KNN.predict(X_test))\nKNN_JaccardIndex = jaccard_score(Y_test, KNN.predict(X_test))\nKNN_F1_Score = f1_score(Y_test, KNN.predict(X_test))\nKNN_LogLoss = log_loss(Y_test, KNN.predict_proba(X_test))\n\nTree_Accuracy = accuracy_score(Y_test, Tree.predict(X_test))\nTree_JaccardIndex = jaccard_score(Y_test, Tree.predict(X_test))\nTree_F1_Score = f1_score(Y_test, Tree.predict(X_test))\nTree_LogLoss = log_loss(Y_test, Tree.predict_proba(X_test))\n\nLR_Accuracy = accuracy_score(Y_test, LR.predict(X_test))\nLR_JaccardIndex = jaccard_score(Y_test, LR.predict(X_test))\nLR_F1_Score = f1_score(Y_test, LR.predict(X_test))\nLR_LogLoss = log_loss(Y_test, LR.predict_proba(X_test))\n\n#SVM_Accuracy = accuracy_score(Y_test, SVM.predict(X_test))\n#SVM_JaccardIndex = jaccard_score(Y_test, SVM.predict(X_test))\n#SVM_F1_Score = f1_score(Y_test, SVM.predict(X_test))\n#SVM_LogLoss = log_loss(Y_test, SVM.predict_proba(X_test))\n\njaccard = jaccard_score(Y_test, predictions)#SVM_JaccardIndex\nf1 = f1_score(Y_test, predictions)\nlogloss = log_loss(Y_test, predictions)\nconf_matrix = confusion_matrix(Y_test, predictions)\naccuracy = accuracy_score(Y_test, predictions)#SVM_Accuracy\n\n\n# Create a dictionary with the metrics\nmetrics_dict = {\n    \"Model\": [\"Linear Regression\", \"KNN\", \"Decision Tree\", \"Logistic Regression\", \"SVM\"],\n    \"MSE\": [mse, None, None, None, None],\n    \"MAE\": [mae, None, None, None, None],\n    \"R2\": [r2, None, None, None, None],\n    \"Accuracy\": [None, KNN_Accuracy, Tree_Accuracy, LR_Accuracy, SVM_Accuracy],\n    \"Jaccard Index\": [None, KNN_JaccardIndex, Tree_JaccardIndex, LR_JaccardIndex, SVM_JaccardIndex],\n    \"F1-Score\": [None, KNN_F1_Score, Tree_F1_Score, LR_F1_Score, SVM_F1_Score],\n    \"Log Loss\": [None, KNN_LogLoss, Tree_LogLoss, LR_LogLoss, logloss]\n}\n\n# Convert the dictionary to a DataFrame\nmetrics_df = pd.DataFrame(metrics_dict)\n\n# Display the DataFrame\nprint(metrics_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                 Model       MSE       MAE        R2  Accuracy  Jaccard Index  \\\n0    Linear Regression  0.280916  0.280916 -0.390658       NaN            NaN   \n1                  KNN       NaN       NaN       NaN  0.818321       0.425121   \n2        Decision Tree       NaN       NaN       NaN  0.749618       0.385768   \n3  Logistic Regression       NaN       NaN       NaN  0.838168       0.518182   \n4                  SVM       NaN       NaN       NaN  0.719084       0.000000   \n\n   F1-Score   Log Loss  \n0       NaN        NaN  \n1  0.596610   2.292757  \n2  0.556757   9.024670  \n3  0.682635   0.357721  \n4  0.000000  10.125240  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}